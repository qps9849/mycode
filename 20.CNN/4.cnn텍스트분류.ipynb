{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "title_arr=[]\n",
    "ctr_arr=[]\n",
    "f=open('c:/data/text/ratings_train.csv', encoding='ms949')\n",
    "reader=csv.reader(f)\n",
    "max_length=0\n",
    "length=0\n",
    "max_idx=0\n",
    "count=0\n",
    "next(reader,None)\n",
    "count_train=0\n",
    "for line in reader:\n",
    "    title_arr.append(line[0])\n",
    "    ctr_arr.append(int(line[1]))\n",
    "    length=len(line[0])\n",
    "    if max_length < length:\n",
    "        max_length=length\n",
    "        max_idx=count\n",
    "    count += 1\n",
    "    count_train+=1\n",
    "    if count_train>=10000: break\n",
    "f.close()\n",
    "\n",
    "f2=open('c:/data/text/ratings_test.csv', encoding='ms949')\n",
    "reader=csv.reader(f2)\n",
    "next(reader, None)\n",
    "count_test=0\n",
    "for line in reader:\n",
    "    title_arr.append(line[0])\n",
    "    ctr_arr.append(int(line[1]))\n",
    "    length=len(line[0])\n",
    "    if max_length < length:\n",
    "        max_length=length\n",
    "        max_idx=count    \n",
    "    count += 1\n",
    "    count_test+=1\n",
    "    if count_test>=10000: break\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_train: 10000\n",
      "count_test: 10000\n",
      "title_arr size: 20000\n",
      "ctr_arr size: 20000\n",
      "max length: 144\n"
     ]
    }
   ],
   "source": [
    "print(\"count_train:\",count_train)\n",
    "print(\"count_test:\",count_test)\n",
    "print(\"title_arr size:\", len(title_arr))\n",
    "print(\"ctr_arr size:\", len(ctr_arr))\n",
    "print(\"max length:\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "step: 1000\n",
      "step: 2000\n",
      "step: 3000\n",
      "step: 4000\n",
      "step: 5000\n",
      "step: 6000\n",
      "step: 7000\n",
      "step: 8000\n",
      "step: 9000\n",
      "step: 10000\n",
      "step: 11000\n",
      "step: 12000\n",
      "step: 13000\n",
      "step: 14000\n",
      "step: 15000\n",
      "step: 16000\n",
      "step: 17000\n",
      "step: 18000\n",
      "step: 19000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt=Okt()\n",
    "title_noun_arr=[]\n",
    "for index, title in enumerate(title_arr):\n",
    "    if index % 1000 == 0:\n",
    "        print('step:',index)\n",
    "    title_noun_arr.append(okt.nouns(title))\n",
    "print(len(title_noun_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "step: 1000\n",
      "step: 2000\n",
      "step: 3000\n",
      "step: 4000\n",
      "step: 5000\n",
      "step: 6000\n",
      "step: 7000\n",
      "step: 8000\n",
      "step: 9000\n",
      "step: 10000\n",
      "step: 11000\n",
      "step: 12000\n",
      "step: 13000\n",
      "step: 14000\n",
      "step: 15000\n",
      "step: 16000\n",
      "step: 17000\n",
      "step: 18000\n",
      "step: 19000\n",
      "[[array([ 2.16547162,  5.36737028,  3.89857429, -4.82951722, -0.60362785,\n",
      "        8.40692668, -0.93490606,  1.91507889, -9.1339213 ,  2.91295141,\n",
      "       -3.59887839,  2.02428279, -7.55017468, -3.42306029, -6.11431754,\n",
      "        5.86803851, -9.35649387, -7.38987405, -4.90957089, -9.40370978,\n",
      "       -9.46280348,  2.2997408 , -4.31620886,  2.11913771,  3.84580555,\n",
      "       -6.82024148, -4.04715844, -3.47613937,  4.36685588,  3.29849647,\n",
      "        6.02980916,  5.11058364, -8.10385832,  0.12264053,  7.03271586,\n",
      "        1.75297475, -7.13720977, -0.90588553,  3.57023212,  5.21939915,\n",
      "       -7.14224558, -6.70684922,  6.1500532 , -8.46531262, -6.90059019,\n",
      "        2.07303028, -6.07435783, -6.96326369,  3.67803007, -2.48668437,\n",
      "        3.33253127,  1.54151064,  6.90561007,  0.15402879, -9.0018789 ,\n",
      "       -5.33019974, -5.55681623,  6.26168626,  0.26912031, -0.5504105 ,\n",
      "        8.68834965, -2.41822762,  7.70710642,  1.80202678,  8.68377381,\n",
      "       -3.27995036, -9.32691116,  1.20379217,  7.15826254,  6.78340564,\n",
      "       -9.29996125, -2.95668434,  1.69820518, -8.20295113, -6.03688518,\n",
      "        7.30249659,  8.39282166,  6.30762589, -7.54456127, -2.2784707 ,\n",
      "       -4.03859138, -0.57559495, -5.93862083,  7.29335447, -6.64699946,\n",
      "       -9.54976931, -8.64090569, -1.54255453, -1.74986309, -7.56323831,\n",
      "       -3.72012433,  3.21839728,  2.01699379,  8.49399358, -0.04935922,\n",
      "       -0.76211127,  7.393466  , -7.9871227 , -2.93081771,  7.23739207]), array([ 1.70821047,  1.76104889,  3.54185057,  6.5198613 , -9.18502229,\n",
      "       -8.51218926,  7.36157857, -1.8583565 ,  7.36352993, -6.15614104,\n",
      "       -7.14038589,  1.62569952,  3.0655919 , -3.32589588,  5.47570357,\n",
      "       -7.4464954 , -6.41060638, -5.86353477,  4.45821164, -6.53059411,\n",
      "       -1.32892438, -8.15491045,  8.88096023, -5.3643269 , -2.61998794,\n",
      "        9.64462994, -0.08941819, -6.29067136,  5.31559377,  0.34888695,\n",
      "       -6.00904962,  9.27678973, -5.62338434, -2.43437544, -6.67703938,\n",
      "        6.96592796,  3.66024747, -5.51845733, -6.89893822, -3.27909755,\n",
      "        4.26998042, -2.38348074, -5.28562938,  8.7287174 , -4.03475942,\n",
      "       -2.03420156, -4.90254415,  9.74883323,  1.02117457,  3.59795265,\n",
      "        9.60408554,  4.00437342,  5.79891989, -8.35078534, -4.11794199,\n",
      "       -9.77041082, -9.22923558, -5.95123519,  4.7702658 , -2.97940546,\n",
      "        9.88741515, -3.17088743,  3.89092116,  4.37413905,  3.95950267,\n",
      "        8.21330727,  0.68881593, -4.94520214,  3.27716094, -7.97636004,\n",
      "        3.9107121 , -8.22141414,  8.35609034, -2.48330058,  8.09765196,\n",
      "       -3.45661778, -3.87016826,  9.20648919,  0.95202953,  3.55845032,\n",
      "       -4.15509001, -0.71584089, -5.18023747, -6.74557465,  6.68601417,\n",
      "       -2.59512849, -8.82018479,  3.99065465, -8.35886106, -5.44479733,\n",
      "        9.94880837,  1.91054038, -6.26129044,  2.85381656,  4.17639034,\n",
      "       -0.51573738, -6.2353329 , -2.08232172, -2.9303729 , -0.75698664]), array([ 8.91348361, -1.95981436, -4.85578526,  4.9327226 , -7.87477827,\n",
      "        2.44244937,  6.97698985, -3.43085077, -7.97515245, -0.74291698,\n",
      "       -2.87231335, -9.73944537,  3.36348101, -3.98569875, -9.79901189,\n",
      "       -2.13975817, -4.90681923,  1.48644362, -0.68802079, -0.31659796,\n",
      "        5.54270636,  8.61673215, -9.22366502,  6.21390246,  6.66681453,\n",
      "       -7.89932839, -4.7931373 ,  6.44176334, -3.06310538, -8.45178235,\n",
      "        7.32832433, -2.71874029,  4.66898001,  4.10445444,  8.75555402,\n",
      "        9.71343968, -7.65993371, -5.31687778,  3.22781944, -3.25856577,\n",
      "       -2.12085361,  4.40016594,  1.25694391,  0.62870469,  1.72314841,\n",
      "        7.9340605 , -2.128096  , -6.59712082,  0.75850548, -9.0371545 ,\n",
      "        5.5465395 ,  4.95700119, -4.56540339,  3.87826741, -7.0231221 ,\n",
      "        3.65832379,  5.00321293,  8.8849136 , -9.8401105 ,  5.09628687,\n",
      "        3.17145031,  5.44303143,  7.49291426,  1.67422802, -2.51992474,\n",
      "       -2.4471031 ,  1.09260489,  9.80029527,  6.26692615, -1.86917869,\n",
      "        5.08709678,  9.63773327,  6.7572508 , -4.08428119,  5.71780619,\n",
      "        1.80242602,  0.21372735,  8.51444157,  3.8598085 , -0.46646762,\n",
      "        2.49299156, -0.88805553, -8.12292603,  7.77029323, -2.27759593,\n",
      "        0.53906186,  0.32412479,  5.71765533,  7.17783305, -9.72047782,\n",
      "        0.61669947,  8.2780151 ,  0.80851829, -6.89265329, -1.19054986,\n",
      "       -5.00942979, -0.76289476, -8.38294775,  4.36691104,  6.7586179 ])]]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "MIN_NOUN_VECTOR_VALUE = -10.0\n",
    "MAX_NOUN_VECTOR_VALUE = 10.0\n",
    "NOUN_VECTOR_SIZE = 100\n",
    "\n",
    "def generate_random_noun_vector():\n",
    "    return np.random.uniform(low=MIN_NOUN_VECTOR_VALUE,high=MAX_NOUN_VECTOR_VALUE,size=(NOUN_VECTOR_SIZE,))\n",
    "w2v_model=gensim.models.Word2Vec.load('c:/data/text/text_100.model')\n",
    "title_noun_vector_arr=[]\n",
    "for index, title_nouns in enumerate(title_noun_arr):\n",
    "    if index % 1000 == 0:\n",
    "        print('step:',index)\n",
    "    noun_vector_arr=[]\n",
    "    for noun in title_nouns:\n",
    "        try:\n",
    "            noun_vector=w2v_model[noun]\n",
    "        except Exception as e:\n",
    "            noun_vector=generate_random_noun_vector()\n",
    "        noun_vector_arr.append(noun_vector)\n",
    "    title_noun_vector_arr.append(noun_vector_arr)\n",
    "print(title_noun_vector_arr[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size=0 \n",
    "min_size=100\n",
    "avg=0\n",
    "count=0\n",
    "sum_size=0\n",
    "\n",
    "for index, title_noun_vector in enumerate(title_noun_vector_arr):\n",
    "    if len(title_noun_vector)==0:\n",
    "        pass\n",
    "    sum_size += len(title_noun_vector)\n",
    "    if max_size < len(title_noun_vector):\n",
    "        max_size=len(title_noun_vector)\n",
    "    if min_size > len(title_noun_vector):\n",
    "        min_size=len(title_noun_vector)\n",
    "    count += 1\n",
    "\n",
    "\n",
    "TITLE_LENGTH=max_size\n",
    "\n",
    "def generate_zero_noun_vector():\n",
    "    return np.random.uniform(low=0.0, high=0.0,size=(NOUN_VECTOR_SIZE,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "step: 1000\n",
      "step: 2000\n",
      "step: 3000\n",
      "step: 4000\n",
      "step: 5000\n",
      "step: 6000\n",
      "step: 7000\n",
      "step: 8000\n",
      "step: 9000\n",
      "step: 10000\n",
      "step: 11000\n",
      "step: 12000\n",
      "step: 13000\n",
      "step: 14000\n",
      "step: 15000\n",
      "step: 16000\n",
      "step: 17000\n",
      "step: 18000\n",
      "step: 19000\n"
     ]
    }
   ],
   "source": [
    "title_noun_vector_arr2=[]\n",
    "for index, title_noun_vector in enumerate(title_noun_vector_arr):\n",
    "    if index % 1000==0:\n",
    "        print('step:',index)\n",
    "    while len(title_noun_vector) < TITLE_LENGTH:\n",
    "        title_noun_vector.append(generate_zero_noun_vector())\n",
    "    title_noun_vector=title_noun_vector[:TITLE_LENGTH]\n",
    "    title_noun_vector_arr2.append(title_noun_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 37\n"
     ]
    }
   ],
   "source": [
    "print(min_size,max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9960, 10040]\n",
      "[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES=2\n",
    "ctr_class_arr=[]\n",
    "ctr_class_count=[0,0]\n",
    "for index, ctr in enumerate(ctr_arr):\n",
    "    if ctr == 0:\n",
    "        ctr_class_arr.append(0.0)\n",
    "        ctr_class_count[0] += 1\n",
    "    elif ctr == 1:\n",
    "        ctr_class_arr.append(1.0)\n",
    "        ctr_class_count[1] += 1\n",
    "print(ctr_class_count)\n",
    "print(ctr_class_arr[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(arr):\n",
    "    sum1=0\n",
    "    for i in arr:\n",
    "        sum1 += i\n",
    "    arr = [float(i)/sum1 for i in arr]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000   10000\n",
      "ctr_class_arr 개수: 20000\n",
      "train 총데이터개수: 10000\n",
      "train 라벨개수: 10000\n",
      "test 총데이터개수: 10000\n",
      "test 라벨개수: 10000\n",
      "train_data_size: 10000\n",
      "test_data_size: 10000\n"
     ]
    }
   ],
   "source": [
    "test_data_size = count_test\n",
    "train_data_size=count_train\n",
    "print(train_data_size,' ',test_data_size)\n",
    "train_input=title_noun_vector_arr[0:train_data_size]\n",
    "train_label=ctr_class_arr[0:train_data_size]\n",
    "test_input=title_noun_vector_arr[train_data_size:]\n",
    "test_label=ctr_class_arr[train_data_size:]\n",
    "\n",
    "print(\"ctr_class_arr 개수:\",len(ctr_class_arr))\n",
    "print(\"train 총데이터개수:\",len(train_input))\n",
    "print(\"train 라벨개수:\",len(train_label))\n",
    "print(\"test 총데이터개수:\",len(test_input))\n",
    "print(\"test 라벨개수:\",len(test_label))\n",
    "print(\"train_data_size:\",train_data_size)\n",
    "print(\"test_data_size:\", test_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input=np.array(train_input)\n",
    "train_input = train_input.reshape(train_input.shape[0],\n",
    "train_input.shape[1],NOUN_VECTOR_SIZE, 1)\n",
    "test_input=np.array(test_input)\n",
    "test_input = test_input.reshape(test_input.shape[0],\n",
    "train_input.shape[1],NOUN_VECTOR_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Input, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_a=Input(shape=(train_input.shape[1],NOUN_VECTOR_SIZE,1),name=\"input-layer\")\n",
    "x=Conv2D(1,(3,3), activation='relu', padding=\"valid\",strides=(1,1))(input_a)\n",
    "x=Conv2D(1,(3,3),activation='relu')(x)\n",
    "x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "x=Dropout(0.25)(x)\n",
    "x=Flatten()(x)\n",
    "x=Dense(128,activation='relu')(x)\n",
    "x=Dropout(0.5)(x)\n",
    "out=Dense(1,activation='sigmoid', name=\"output-layer\")(x)\n",
    "model=Model(inputs=[input_a], outputs=out)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "30/30 [==============================] - 4s 135ms/step - loss: 0.8368 - accuracy: 0.4982 - val_loss: 0.7033 - val_accuracy: 0.4924\n",
      "Epoch 2/5\n",
      "30/30 [==============================] - 4s 140ms/step - loss: 0.7023 - accuracy: 0.5269 - val_loss: 0.6982 - val_accuracy: 0.5040\n",
      "Epoch 3/5\n",
      "30/30 [==============================] - 4s 137ms/step - loss: 0.6919 - accuracy: 0.5318 - val_loss: 0.6972 - val_accuracy: 0.5088\n",
      "Epoch 4/5\n",
      "30/30 [==============================] - 4s 142ms/step - loss: 0.6854 - accuracy: 0.5487 - val_loss: 0.6967 - val_accuracy: 0.5148\n",
      "Epoch 5/5\n",
      "30/30 [==============================] - 4s 144ms/step - loss: 0.6846 - accuracy: 0.5378 - val_loss: 0.6961 - val_accuracy: 0.5192\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping=EarlyStopping(patience=2)\n",
    "hist=model.fit(x=train_input,y=np.array(train_label),validation_split=0.25,\n",
    "batch_size=256,epochs=5,verbose=1,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.6600\n",
      "loss: 69.51%\n",
      "accuracy: 66.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(np.array(test_input)[:100],np.array(test_label)[:100], \n",
    "batch_size=1, verbose=1)\n",
    "\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "m2 = Model(inputs=model.input,outputs=model.get_layer('output-layer').output)\n",
    "y = m2.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5031466 ],\n",
       "       [0.5031466 ],\n",
       "       [0.48189238],\n",
       "       [0.4919833 ],\n",
       "       [0.48896223],\n",
       "       [0.5515713 ],\n",
       "       [0.5031466 ],\n",
       "       [0.50367993],\n",
       "       [0.5020647 ],\n",
       "       [0.42262545]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:/data/text\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('c:/data/text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5031466]]\n",
      "1.0\n",
      "재밌군\n"
     ]
    }
   ],
   "source": [
    "n=911\n",
    "print(model.predict(np.array(train_input)[n].reshape(1, 37, 100, 1)))\n",
    "print(np.array(train_label)[n])\n",
    "print(title_arr[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5188263]]\n",
      "0.0\n",
      "OOO기 영화입니다. 긴장감도 그렇게 없고 반전도 안놀랍고 시간이 아까운 영화입니다.\n"
     ]
    }
   ],
   "source": [
    "n=5000\n",
    "print(model.predict(np.array(train_input)[n].reshape(1, 37, 100, 1)))\n",
    "print(np.array(test_label)[n])\n",
    "print(title_arr[n+10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cef9e06bb236b2a8629b07e87a04b187b952a0f661eff5533360a155783f0c33"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
